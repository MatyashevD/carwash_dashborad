import streamlit as st
import pandas as pd
import numpy as np

YANDEX_PHONE = "133133133133"


@st.cache_data
def load_data(file) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç CSV –≤ —Ñ–æ—Ä–º–∞—Ç–µ orderTable, –ø—Ä–∏–≤–æ–¥–∏—Ç —á–∏—Å–ª–∞ –∏ –¥–∞—Ç—ã."""
    # –ß–∏—Ç–∞–µ–º CSV –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é –≤ —Ç–µ–ª–µ—Ñ–æ–Ω–∞—Ö
    df = pd.read_csv(file, sep=";", encoding="utf-8-sig", dtype=str)

    # –ü—Ä–∏–≤–æ–¥–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    num_cols = [
        "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å",
        "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏",
        "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏",
        "–ù–∞—á–∏—Å–ª–µ–Ω–æ –∫–µ—à–±–µ–∫–∞",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace("\u00a0", " ", regex=False)
                .str.replace(" ", "", regex=False)
                .str.replace(",", ".", regex=False)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0.0)

    # –î–∞—Ç—ã / –≤—Ä–µ–º—è
    df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"] = pd.to_datetime(df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"], errors="coerce")
    df["date"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.date
    df["hour"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.hour
    df["weekday"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.weekday

    # –ò—Ç–æ–≥–æ–≤—ã–π —á–µ–∫
    df["total"] = df.get("–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏", 0) + df.get("–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏", 0)

    # –ö–ª—é—á –º–æ–π–∫–∏ (–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å)
    df["–ü–∞—Ä—Ç–Ω—ë—Ä"] = df["–ü–∞—Ä—Ç–Ω—ë—Ä"].fillna("")
    df["–ê–≤—Ç–æ–º–æ–π–∫–∞"] = df["–ê–≤—Ç–æ–º–æ–π–∫–∞"].fillna("")
    df["–ê–¥—Ä–µ—Å"] = df["–ê–¥—Ä–µ—Å"].fillna("")
    df["wash_key"] = df["–ü–∞—Ä—Ç–Ω—ë—Ä"] + " | " + df["–ê–≤—Ç–æ–º–æ–π–∫–∞"] + " | " + df["–ê–¥—Ä–µ—Å"]

    return df


def normalize_phone(phone) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é –∏ —É–±–∏—Ä–∞–µ—Ç –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã."""
    phone_str = str(phone).strip()
    
    # –ï—Å–ª–∏ —ç—Ç–æ NaN –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    if phone_str.lower() in ['nan', 'none', '']:
        return ""
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1.33133e+11" –∏–ª–∏ "1,33133E+11")
    try:
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
        phone_clean = phone_str.replace(",", ".")
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ float, –∑–∞—Ç–µ–º –≤ int
        phone_float = float(phone_clean)
        phone_int = int(phone_float)
        return str(phone_int)
    except (ValueError, OverflowError):
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å (–Ω–µ —á–∏—Å–ª–æ), —É–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
        phone_str = ''.join(filter(str.isdigit, phone_str))
        return phone_str


def categorize_by_phone(phone: str) -> str:
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É: –Ø–Ω–¥–µ–∫—Å (133133133133) –∏–ª–∏ –õ–µ–π–∫–∞ (–≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ)."""
    phone_normalized = normalize_phone(phone)
    if phone_normalized == YANDEX_PHONE:
        return "–Ø–Ω–¥–µ–∫—Å"
    return "–õ–µ–π–∫–∞"


def get_period_label(df):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if df.empty or "date" not in df.columns:
        return None
    
    dates = df["date"].dropna()
    if dates.empty:
        return None
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º date –≤ datetime –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–µ—Ä–∏–æ–¥–∞–º–∏
    dates_dt = pd.to_datetime(dates)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Å—è—Ü (—Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –º–µ—Å—è—Ü –≤ –¥–∞–Ω–Ω—ã—Ö)
    months = dates_dt.dt.to_period("M")
    main_month = months.mode()
    
    if len(main_month) > 0:
        month_period = main_month[0]
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º: "–Ω–æ—è–±—Ä—å 2024"
        month_names = {
            1: "—è–Ω–≤–∞—Ä—å", 2: "—Ñ–µ–≤—Ä–∞–ª—å", 3: "–º–∞—Ä—Ç", 4: "–∞–ø—Ä–µ–ª—å",
            5: "–º–∞–π", 6: "–∏—é–Ω—å", 7: "–∏—é–ª—å", 8: "–∞–≤–≥—É—Å—Ç",
            9: "—Å–µ–Ω—Ç—è–±—Ä—å", 10: "–æ–∫—Ç—è–±—Ä—å", 11: "–Ω–æ—è–±—Ä—å", 12: "–¥–µ–∫–∞–±—Ä—å"
        }
        month_name = month_names[month_period.month]
        year = month_period.year
        return f"{month_name} {year}"
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Å—è—Ü, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
    min_date = dates.min()
    max_date = dates.max()
    if min_date == max_date:
        return min_date.strftime("%d.%m.%Y")
    else:
        return f"{min_date.strftime('%d.%m.%Y')} - {max_date.strftime('%d.%m.%Y')}"


def group_transactions_to_visits(df, time_window_minutes=30):
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –≤–∏–∑–∏—Ç—ã.
    –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö time_window_minutes —Å—á–∏—Ç–∞—é—Ç—Å—è –æ–¥–Ω–∏–º –≤–∏–∑–∏—Ç–æ–º.
    
    Returns:
        DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π 'visit_total' - —Å—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ —Ä–∞–º–∫–∞—Ö –≤–∏–∑–∏—Ç–∞
    """
    if df.empty or "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã" not in df.columns or "–¢–µ–ª–µ—Ñ–æ–Ω" not in df.columns:
        return df
    
    df_work = df.copy()
    # –£–±–∏—Ä–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –¥–∞—Ç—ã –∏–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞
    df_work = df_work.dropna(subset=["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã", "–¢–µ–ª–µ—Ñ–æ–Ω"])
    if df_work.empty:
        return pd.DataFrame(columns=["visit_id", "visit_total", "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏", "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏", "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "–¢–µ–ª–µ—Ñ–æ–Ω", "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"])
    
    df_work = df_work.sort_values(["–¢–µ–ª–µ—Ñ–æ–Ω", "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"])
    
    # –°–æ–∑–¥–∞—ë–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–∏–∑–∏—Ç–∞
    df_work["visit_id"] = None
    
    current_visit_id = 0
    last_phone = None
    last_datetime = None
    
    for idx, row in df_work.iterrows():
        phone = str(row["–¢–µ–ª–µ—Ñ–æ–Ω"]).strip()
        current_datetime = row["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"]
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω–∞
        if pd.isna(current_datetime):
            continue
        
        # –ï—Å–ª–∏ –Ω–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç –∏–ª–∏ –ø—Ä–æ—à–ª–æ –±–æ–ª—å—à–µ time_window_minutes —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        if (last_phone is None or 
            phone != last_phone or 
            last_datetime is None or
            (current_datetime - last_datetime).total_seconds() / 60 > time_window_minutes):
            current_visit_id += 1
        
        df_work.at[idx, "visit_id"] = current_visit_id
        last_phone = phone
        last_datetime = current_datetime
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≤–∏–∑–∏—Ç–∞–º –∏ —Å—É–º–º–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    visits = (
        df_work.groupby("visit_id")
        .agg({
            "total": "sum",
            "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏": "sum",
            "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏": "sum",
            "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å": "sum",
            "–¢–µ–ª–µ—Ñ–æ–Ω": "first",
            "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã": "first"
        })
        .reset_index()
    )
    visits = visits.rename(columns={"total": "visit_total"})
    
    return visits


def calculate_ltv(df):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç LTV (Lifetime Value) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.
    LTV = —Å—É–º–º–∞ –≤—Å–µ—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∫–ª–∏–µ–Ω—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥.
    
    Returns:
        DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: –¢–µ–ª–µ—Ñ–æ–Ω, LTV, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–∑–∏—Ç–æ–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    """
    if df.empty or "–¢–µ–ª–µ—Ñ–æ–Ω" not in df.columns or "total" not in df.columns:
        return pd.DataFrame(columns=["–¢–µ–ª–µ—Ñ–æ–Ω", "LTV", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–∑–∏—Ç–æ–≤", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"])
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –≤–∏–∑–∏—Ç—ã
    visits = group_transactions_to_visits(df, time_window_minutes=30)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º LTV –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º (—Å—É–º–º–∞ –≤—Å–µ—Ö –≤–∏–∑–∏—Ç–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞)
    ltv_by_client = (
        visits.groupby("–¢–µ–ª–µ—Ñ–æ–Ω")
        .agg({
            "visit_total": "sum",  # LTV = —Å—É–º–º–∞ –≤—Å–µ—Ö –≤–∏–∑–∏—Ç–æ–≤
            "visit_id": "count"    # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–∑–∏—Ç–æ–≤
        })
        .reset_index()
        .rename(columns={"visit_total": "LTV", "visit_id": "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–∑–∏—Ç–æ–≤"})
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
    transaction_count = (
        df.groupby("–¢–µ–ª–µ—Ñ–æ–Ω")
        .size()
        .reset_index(name="–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    )
    
    ltv_by_client = ltv_by_client.merge(transaction_count, on="–¢–µ–ª–µ—Ñ–æ–Ω", how="left")
    ltv_by_client = ltv_by_client.sort_values("LTV", ascending=False)
    
    return ltv_by_client


def compare_washes(df1, df2, name1, name2):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–π–∫–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞–º–∏."""
    washes1 = set(df1["wash_key"].dropna().unique())
    washes2 = set(df2["wash_key"].dropna().unique())
    
    only_in_1 = washes1 - washes2  # –ú–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º —Ñ–∞–π–ª–µ
    only_in_2 = washes2 - washes1  # –ú–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ç–æ—Ä–æ–º —Ñ–∞–π–ª–µ
    common = washes1 & washes2      # –û–±—â–∏–µ –º–æ–π–∫–∏
    
    return {
        "only_in_1": sorted(only_in_1),
        "only_in_2": sorted(only_in_2),
        "common": sorted(common),
        "count_1": len(washes1),
        "count_2": len(washes2),
        "count_common": len(common),
    }


def main():
    st.set_page_config(page_title="Carwash Dashboard", layout="wide")
    st.title("–î–∞—à–±–æ—Ä–¥ –ø–æ –∞–≤—Ç–æ–º–æ–π–∫–∞–º (orderTable)")

    st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö CSV
    uploaded_files = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV-—Ñ–∞–π–ª–æ–≤ `orderTable`",
        type=["csv"],
        accept_multiple_files=True,
    )

    if not uploaded_files:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV-—Ñ–∞–π–ª, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –¥–∞—à–±–æ—Ä–¥.")
        st.stop()

    # –í—ã–±–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    file_labels = [f.name for f in uploaded_files]
    selected_label = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", file_labels)
    selected_file = next(f for f in uploaded_files if f.name == selected_label)

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ)
    if len(uploaded_files) > 1:
        st.sidebar.markdown("---")
        st.sidebar.subheader("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤")
        
        compare_file1 = st.sidebar.selectbox(
            "–ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª (–±–∞–∑–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥)",
            file_labels,
            index=0,
            key="compare_file1"
        )
        compare_file2 = st.sidebar.selectbox(
            "–í—Ç–æ—Ä–æ–π —Ñ–∞–π–ª (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–π –ø–µ—Ä–∏–æ–¥)",
            file_labels,
            index=min(1, len(file_labels) - 1),
            key="compare_file2"
        )
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤
        if compare_file1 != compare_file2:
            df1_compare = load_data(next(f for f in uploaded_files if f.name == compare_file1))
            df2_compare = load_data(next(f for f in uploaded_files if f.name == compare_file2))
            
            comparison = compare_washes(df1_compare, df2_compare, compare_file1, compare_file2)
            
            st.sidebar.write(f"**{compare_file1}:** {comparison['count_1']} –º–æ–µ–∫")
            st.sidebar.write(f"**{compare_file2}:** {comparison['count_2']} –º–æ–µ–∫")
            st.sidebar.write(f"**–û–±—â–∏—Ö –º–æ–µ–∫:** {comparison['count_common']}")
            
            if len(comparison['only_in_1']) > 0:
                st.sidebar.warning(f"‚ö†Ô∏è **–ò—Å—á–µ–∑–ª–æ –º–æ–µ–∫:** {len(comparison['only_in_1'])}")
            if len(comparison['only_in_2']) > 0:
                st.sidebar.info(f"‚ÑπÔ∏è **–ü–æ—è–≤–∏–ª–æ—Å—å –º–æ–µ–∫:** {len(comparison['only_in_2'])}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ session state –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            st.session_state['comparison'] = comparison
            st.session_state['compare_names'] = (compare_file1, compare_file2)

    df = load_data(selected_file)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –î–û —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    df = df.assign(
        partner_category=df["–¢–µ–ª–µ—Ñ–æ–Ω"].apply(categorize_by_phone)
    )
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏)
    with st.sidebar.expander("üîç –û—Ç–ª–∞–¥–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏", expanded=False):
        st.write(f"**–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df)}")
        st.write(f"**–õ–µ–π–∫–∞:** {len(df[df['partner_category'] == '–õ–µ–π–∫–∞'])}")
        st.write(f"**–Ø–Ω–¥–µ–∫—Å:** {len(df[df['partner_category'] == '–Ø–Ω–¥–µ–∫—Å'])}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        sample_phones = df["–¢–µ–ª–µ—Ñ–æ–Ω"].head(10).apply(normalize_phone).unique()
        st.write(f"**–ü—Ä–∏–º–µ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ (–ø–µ—Ä–≤—ã–µ 10):**")
        for phone in sample_phones[:10]:
            st.write(f"- `{phone}`")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω 133133133133 –≤ –¥–∞–Ω–Ω—ã—Ö
        all_phones_normalized = df["–¢–µ–ª–µ—Ñ–æ–Ω"].apply(normalize_phone)
        yandex_count = (all_phones_normalized == YANDEX_PHONE).sum()
        st.write(f"**–ó–∞–ø–∏—Å–µ–π —Å —Ç–µ–ª–µ—Ñ–æ–Ω–æ–º {YANDEX_PHONE}:** {yandex_count}")

    st.sidebar.markdown("---")
    st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")

    # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
    min_date = df["date"].min()
    max_date = df["date"].max()
    date_range = st.sidebar.date_input(
        "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
    )
    if isinstance(date_range, tuple):
        start_date, end_date = date_range
    else:
        start_date = end_date = date_range

    # –ò—Å–∫–ª—é—á–∏—Ç—å –Ø–Ω–¥–µ–∫—Å
    exclude_yandex = st.sidebar.checkbox(
        "–ò—Å–∫–ª—é—á–∏—Ç—å –Ø–Ω–¥–µ–∫—Å (133133133133)", value=False
    )

    filtered = df.copy()
    if exclude_yandex:
        filtered = filtered[filtered["partner_category"] != "–Ø–Ω–¥–µ–∫—Å"]

    # –§–∏–ª—å—Ç—Ä—ã –ø–æ –ø–∞—Ä—Ç–Ω—ë—Ä—É / –∞–≤—Ç–æ–º–æ–π–∫–µ / –∞–¥—Ä–µ—Å—É
    partners = sorted(
        [p for p in filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].dropna().unique().tolist() if p]
    )
    partner_sel = st.sidebar.multiselect("–ü–∞—Ä—Ç–Ω—ë—Ä", partners)

    washes = sorted(
        [w for w in filtered["–ê–≤—Ç–æ–º–æ–π–∫–∞"].dropna().unique().tolist() if w]
    )
    wash_sel = st.sidebar.multiselect("–ê–≤—Ç–æ–º–æ–π–∫–∞", washes)

    addresses = sorted(
        [a for a in filtered["–ê–¥—Ä–µ—Å"].dropna().unique().tolist() if a]
    )
    addr_sel = st.sidebar.multiselect("–ê–¥—Ä–µ—Å", addresses)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
    mask = (filtered["date"] >= start_date) & (filtered["date"] <= end_date)

    if partner_sel:
        mask &= filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].isin(partner_sel)
    if wash_sel:
        mask &= filtered["–ê–≤—Ç–æ–º–æ–π–∫–∞"].isin(wash_sel)
    if addr_sel:
        mask &= filtered["–ê–¥—Ä–µ—Å"].isin(addr_sel)

    filtered = filtered[mask]

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
    period_label = get_period_label(filtered)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –≤–∏—Ç—Ä–∏–Ω–µ
    if period_label:
        st.info(f"üìÖ **–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:** {period_label.capitalize()} | –§–∞–π–ª: {selected_label} | –ó–∞–ø–∏—Å–µ–π: **{len(filtered)}**")
    else:
        st.caption(
            f"–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: **{selected_label}**, –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤: **{len(filtered)}**"
        )

    if filtered.empty:
        st.warning("–ü–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        st.stop()

    # --- KPI-–±–ª–æ–∫ ---
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ KPI, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª—ë–Ω
    if period_label:
        st.subheader(f"–û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∑–∞ {period_label}")
    else:
        st.subheader("–û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")

    unique_clients = (
        filtered["–¢–µ–ª–µ—Ñ–æ–Ω"].astype(str).str.strip().nunique()
    )
    unique_washes_partner_addr = (
        filtered[["–ü–∞—Ä—Ç–Ω—ë—Ä", "–ê–¥—Ä–µ—Å"]]
        .dropna(subset=["–ê–¥—Ä–µ—Å"])
        .drop_duplicates()
        .shape[0]
    )

    total_cash = filtered["–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏"].sum()
    total_bonus = filtered["–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏"].sum()
    total_sum = filtered["total"].sum()
    cashback_sum = filtered["–ù–∞—á–∏—Å–ª–µ–Ω–æ –∫–µ—à–±–µ–∫–∞"].sum()

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –≤–∏–∑–∏—Ç—ã (—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 30 –º–∏–Ω—É—Ç = –æ–¥–∏–Ω –≤–∏–∑–∏—Ç)
    visits = group_transactions_to_visits(filtered, time_window_minutes=30)
    
    # –°—Ä–µ–¥–Ω–∏–π —á–µ–∫ —Å—á–∏—Ç–∞–µ–º –ø–æ –≤–∏–∑–∏—Ç–∞–º, –∞ –Ω–µ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º
    avg_check = visits["visit_total"].mean() if len(visits) > 0 else 0.0
    median_check = visits["visit_total"].median() if len(visits) > 0 else 0.0
    
    # –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–∫–∂–µ —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫ –ø–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º (—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±)
    avg_check_by_transactions = filtered["total"].mean()
    
    bonus_share = total_bonus / total_sum * 100 if total_sum > 0 else 0.0

    col1, col2, col3, col4 = st.columns(4)
    col1.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã",
        f"{unique_clients:,}".replace(",", " "),
    )
    col2.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–π–∫–∏ (–ü–∞—Ä—Ç–Ω—ë—Ä+–ê–¥—Ä–µ—Å)",
        f"{unique_washes_partner_addr}",
    )
    col3.metric(
        "–í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π",
        f"{len(filtered):,}".replace(",", " "),
    )
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫ –ø–æ –≤–∏–∑–∏—Ç–∞–º —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –≤–∏–∑–∏—Ç–æ–≤
    num_visits = len(visits)
    num_transactions = len(filtered)
    col4.metric(
        "–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ (‚ÇΩ)",
        f"{avg_check:,.2f}".replace(",", " "),
        help=f"–ü–æ –≤–∏–∑–∏—Ç–∞–º (–≤–∏–∑–∏—Ç–æ–≤: {num_visits:,}, —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {num_transactions:,})"
    )

    col5, col6, col7, col8 = st.columns(4)
    col5.metric(
        "–ò—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ (‚ÇΩ)",
        f"{total_sum:,.0f}".replace(",", " "),
    )
    col6.metric(
        "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏ (‚ÇΩ)",
        f"{total_cash:,.0f}".replace(",", " "),
    )
    col7.metric(
        "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏ (‚ÇΩ)",
        f"{total_bonus:,.0f}".replace(",", " "),
    )
    col8.metric("–î–æ–ª—è –±–æ–Ω—É—Å–æ–≤ (%)", f"{bonus_share:.2f}")

    st.markdown(
        f"**–ú–µ–¥–∏–∞–Ω–Ω—ã–π —á–µ–∫:** {median_check:.2f} ‚ÇΩ &nbsp;&nbsp;|&nbsp;&nbsp; "
        f"**–°—É–º–º–∞ –∫–µ—à–±–µ–∫–∞:** {cashback_sum:,.0f} ‚ÇΩ".replace(",", " ")
    )

    # –í—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å" –∫–∞–∫ –≤ –≥—Ä–∞—Ñ–∏–∫–µ)
    leyka_total = filtered.loc[
        filtered["partner_category"] == "–õ–µ–π–∫–∞", "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å"
    ].sum()
    yandex_total = filtered.loc[
        filtered["partner_category"] == "–Ø–Ω–¥–µ–∫—Å", "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å"
    ].sum()
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    leyka_count = len(filtered[filtered["partner_category"] == "–õ–µ–π–∫–∞"])
    yandex_count = len(filtered[filtered["partner_category"] == "–Ø–Ω–¥–µ–∫—Å"])
    
    col_partner1, col_partner2 = st.columns(2)
    col_partner1.metric(
        "–í—ã—Ä—É—á–∫–∞ –õ–µ–π–∫–∞ (‚ÇΩ)",
        f"{leyka_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {leyka_count}"
    )
    col_partner2.metric(
        "–í—ã—Ä—É—á–∫–∞ –Ø–Ω–¥–µ–∫—Å (‚ÇΩ)",
        f"{yandex_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {yandex_count}"
    )

    # --- –ü–æ–¥–ø–∏—Å–∫–∏ (FranchisingGroup) ---
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø–∞—Ä—Ç–Ω—ë—Ä–æ–º FranchisingGroup (—É—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è)
    subscription_mask = filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].astype(str).str.strip().str.lower().str.contains("franchisinggroup", case=False, na=False)
    subscription_data = filtered[subscription_mask]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏" –¥–ª—è —Å—É–º–º—ã –ø–æ–¥–ø–∏—Å–æ–∫
    subscription_total = subscription_data["–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏"].sum()
    subscription_unique_clients = subscription_data["–¢–µ–ª–µ—Ñ–æ–Ω"].astype(str).str.strip().nunique()
    subscription_count = len(subscription_data)
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    unique_partners = filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].astype(str).str.strip().unique()
    franchising_partners = [p for p in unique_partners if "franchisinggroup" in str(p).lower()]
    
    st.markdown("---")
    st.subheader("üìã –ü–æ–¥–ø–∏—Å–∫–∏ (FranchisingGroup)")
    col_sub1, col_sub2 = st.columns(2)
    col_sub1.metric(
        "–°—É–º–º–∞ –æ–ø–ª–∞—á–µ–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫ (‚ÇΩ)",
        f"{subscription_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {subscription_count}"
    )
    col_sub2.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–æ–¥–ø–∏—Å–∫–æ–π",
        f"{subscription_unique_clients:,}".replace(",", " "),
        help=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –µ—Å–ª–∏ —Å—É–º–º–∞ = 0
    if subscription_total == 0 and subscription_count == 0:
        with st.expander("üîç –û—Ç–ª–∞–¥–∫–∞: –ø–æ—á–µ–º—É –ø–æ–¥–ø–∏—Å–∫–∏ = 0?", expanded=False):
            st.write(f"**–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å FranchisingGroup:** {subscription_count}")
            st.write(f"**–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—Ç–Ω—ë—Ä—ã –≤ –¥–∞–Ω–Ω—ã—Ö:** {len(unique_partners)}")
            if franchising_partners:
                st.write(f"**–ü–∞—Ä—Ç–Ω—ë—Ä—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'franchisinggroup':** {franchising_partners}")
            else:
                st.write("**–ü–∞—Ä—Ç–Ω—ë—Ä—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'franchisinggroup':** –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                st.write("**–ü—Ä–∏–º–µ—Ä—ã –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 10):**")
                for partner in unique_partners[:10]:
                    st.write(f"- `{partner}`")

    # --- LTV (Lifetime Value) –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
    st.markdown("---")
    st.subheader("üí∞ LTV –∫–ª–∏–µ–Ω—Ç–æ–≤ (Lifetime Value)")
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º LTV –¥–ª—è –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
    ltv_data = calculate_ltv(filtered)
    
    if len(ltv_data) > 0:
        avg_ltv = ltv_data["LTV"].mean()
        median_ltv = ltv_data["LTV"].median()
        total_clients_with_ltv = len(ltv_data)
        
        col_ltv1, col_ltv2, col_ltv3 = st.columns(3)
        col_ltv1.metric(
            "–°—Ä–µ–¥–Ω–∏–π LTV (‚ÇΩ)",
            f"{avg_ltv:,.2f}".replace(",", " "),
            help=f"–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ LTV –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤"
        )
        col_ltv2.metric(
            "–ú–µ–¥–∏–∞–Ω–Ω—ã–π LTV (‚ÇΩ)",
            f"{median_ltv:,.2f}".replace(",", " "),
            help=f"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ LTV –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤"
        )
        col_ltv3.metric(
            "–ö–ª–∏–µ–Ω—Ç–æ–≤ —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏",
            f"{total_clients_with_ltv:,}".replace(",", " "),
            help=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤"
        )
        
        # –¢–æ–ø-10 –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ LTV (–∏—Å–∫–ª—é—á–∞–µ–º –Ø–Ω–¥–µ–∫—Å –∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ —Ç–æ–ª—å–∫–æ —Å –±–æ–Ω—É—Å–∞–º–∏)
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ø–Ω–¥–µ–∫—Å–∞ (—Ç–µ–ª–µ—Ñ–æ–Ω 133133133133)
        ltv_data_filtered = ltv_data[
            ltv_data["–¢–µ–ª–µ—Ñ–æ–Ω"].apply(normalize_phone) != YANDEX_PHONE
        ].copy()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ–ø–ª–∞—á–∏–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ –±–æ–Ω—É—Å–∞–º–∏ (–≤–ª–∞–¥–µ–ª—å—Ü—ã/–æ–ø–µ—Ä–∞—Ç–æ—Ä—ã)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –∫–ª–∏–µ–Ω—Ç–∞ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è —Å –æ–ø–ª–∞—Ç–æ–π –¥–µ–Ω—å–≥–∞–º–∏
        clients_with_cash = (
            filtered.groupby("–¢–µ–ª–µ—Ñ–æ–Ω")["–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏"]
            .sum()
            .reset_index()
        )
        clients_with_cash = clients_with_cash[
            clients_with_cash["–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏"] > 0
        ]["–¢–µ–ª–µ—Ñ–æ–Ω"].tolist()
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –æ–ø–ª–∞—Ç–∞ –¥–µ–Ω—å–≥–∞–º–∏
        ltv_data_filtered = ltv_data_filtered[
            ltv_data_filtered["–¢–µ–ª–µ—Ñ–æ–Ω"].isin(clients_with_cash)
        ].copy()
        
        st.markdown("**–¢–æ–ø-10 –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ LTV (–±–µ–∑ –Ø–Ω–¥–µ–∫—Å –∏ —Ç–æ–ª—å–∫–æ –±–æ–Ω—É—Å–Ω—ã—Ö):**")
        top_10_ltv = ltv_data_filtered.head(10).copy()
        top_10_ltv_display = top_10_ltv.copy()
        top_10_ltv_display["LTV_formatted"] = top_10_ltv_display["LTV"].apply(lambda x: f"{x:,.2f}".replace(",", " "))
        top_10_ltv_display = top_10_ltv_display.rename(columns={
            "–¢–µ–ª–µ—Ñ–æ–Ω": "–¢–µ–ª–µ—Ñ–æ–Ω",
            "LTV_formatted": "LTV (‚ÇΩ)",
            "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–∑–∏—Ç–æ–≤": "–í–∏–∑–∏—Ç–æ–≤",
            "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π": "–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"
        })
        st.dataframe(
            top_10_ltv_display[["–¢–µ–ª–µ—Ñ–æ–Ω", "LTV (‚ÇΩ)", "–í–∏–∑–∏—Ç–æ–≤", "–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"]],
            use_container_width=True,
            hide_index=True
        )
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ LTV.")

    # --- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ KPI) ---
    if 'comparison' in st.session_state and 'compare_names' in st.session_state:
        comparison = st.session_state['comparison']
        name1, name2 = st.session_state['compare_names']
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—á–µ–∑–Ω—É–≤—à–∏–µ –º–æ–π–∫–∏ —Å—Ä–∞–∑—É, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if comparison['only_in_1']:
            st.markdown("---")
            st.error(f"‚ö†Ô∏è **–í–ù–ò–ú–ê–ù–ò–ï: {len(comparison['only_in_1'])} –º–æ–π–∫–∞(–∏) –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ {name2} –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å {name1}**")
            
            st.subheader(f"‚ùå –ú–æ–π–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å—á–µ–∑–ª–∏ –≤ {name2}:")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            missing_washes_df = pd.DataFrame({
                "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å": comparison['only_in_1']
            })
            st.dataframe(missing_washes_df, use_container_width=True, hide_index=True)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            col_comp1, col_comp2, col_comp3 = st.columns(3)
            col_comp1.metric(f"–ú–æ–µ–∫ –≤ {name1}", comparison['count_1'])
            col_comp2.metric(f"–ú–æ–µ–∫ –≤ {name2}", comparison['count_2'])
            col_comp3.metric("–û–±—â–∏—Ö –º–æ–µ–∫", comparison['count_common'])
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—è–≤–∏–≤—à–∏–µ—Å—è –º–æ–π–∫–∏ (–º–µ–Ω–µ–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
        if comparison['only_in_2']:
            st.markdown("---")
            st.info(f"‚ÑπÔ∏è **–ù–æ–≤—ã–µ –º–æ–π–∫–∏ –≤ {name2} ({len(comparison['only_in_2'])}):**")
            new_washes_df = pd.DataFrame({
                "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å": comparison['only_in_2']
            })
            st.dataframe(new_washes_df, use_container_width=True, hide_index=True)

    # --- –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –¥–Ω—è–º ---
    st.markdown("---")
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –¥–Ω—è–º")

    daily = (
        filtered.groupby("date")
        .agg(
            orders=("‚Ññ", "count"),
            revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"),
        )
        .reset_index()
        .sort_values("date")
    )

    col_d1, col_d2 = st.columns(2)
    col_d1.line_chart(
        daily.set_index("date")["orders"], use_container_width=True
    )
    col_d1.caption("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤ –ø–æ –¥–Ω—è–º")

    col_d2.line_chart(
        daily.set_index("date")["revenue"], use_container_width=True
    )
    col_d2.caption("–í—ã—Ä—É—á–∫–∞ –ø–æ –¥–Ω—è–º (–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å)")

    st.markdown("---")
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –≤—ã—Ä—É—á–∫–∏ –õ–µ–π–∫–∞ vs –Ø–Ω–¥–µ–∫—Å")

    partner_daily = (
        filtered[filtered["partner_category"].isin(["–õ–µ–π–∫–∞", "–Ø–Ω–¥–µ–∫—Å"])]
        .groupby(["date", "partner_category"])
        .agg(revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"))
        .reset_index()
    )

    if partner_daily.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –õ–µ–π–∫–∞ –∏ –Ø–Ω–¥–µ–∫—Å.")
    else:
        partner_pivot = (
            partner_daily.pivot(
                index="date", columns="partner_category", values="revenue"
            )
            .fillna(0)
            .sort_index()
        )
        st.line_chart(partner_pivot, use_container_width=True)
        st.caption(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—É–º–º–∞—Ä–Ω–æ–π –≤—ã—Ä—É—á–∫–∏ (–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å) –ø–æ –¥–Ω—è–º –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –õ–µ–π–∫–∞ –∏ –Ø–Ω–¥–µ–∫—Å."
        )

    # --- –¢–æ–ø –º–æ–π–∫–∏ ---
    st.markdown("---")
    st.subheader("–¢–æ–ø‚Äë–º–æ–π–∫–∏")

    top_wash = (
        filtered.groupby("wash_key")
        .agg(
            orders=("‚Ññ", "count"),
            revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"),
            avg_check=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "mean"),
        )
        .reset_index()
        .sort_values("revenue", ascending=False)
    )

    st.markdown("**–¢–æ–ø‚Äë10 –º–æ–µ–∫ –ø–æ –≤—ã—Ä—É—á–∫–µ:**")
    st.dataframe(
        top_wash.head(10).rename(
            columns={
                "wash_key": "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å",
                "orders": "–ó–∞–∫–∞–∑–æ–≤",
                "revenue": "–í—ã—Ä—É—á–∫–∞",
                "avg_check": "–°—Ä. —á–µ–∫",
            }
        ),
        use_container_width=True,
    )

    # --- –í—ã–±—Ä–æ—Å—ã ---
    st.markdown("---")
    st.subheader("–í—ã–±—Ä–æ—Å—ã –ø–æ —Å—É–º–º–µ —á–µ–∫–∞")

    amounts = filtered["total"].values
    q1 = np.percentile(amounts, 25)
    q3 = np.percentile(amounts, 75)
    iqr = q3 - q1
    upper = q3 + 1.5 * iqr
    outliers = filtered[filtered["total"] > upper]

    st.markdown(
        f"Q1 = {q1:.2f} ‚ÇΩ, Q3 = {q3:.2f} ‚ÇΩ, –ø–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–∞ = {upper:.2f} ‚ÇΩ, "
        f"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ = {len(outliers)}"
    )

    show_outliers = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –≤—ã–±—Ä–æ—Å–æ–≤", value=False)
    if show_outliers and not outliers.empty:
        st.dataframe(
            outliers[
                [
                    "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã",
                    "–¢–µ–ª–µ—Ñ–æ–Ω",
                    "–ö–ª–∏–µ–Ω—Ç",
                    "–ü–∞—Ä—Ç–Ω—ë—Ä",
                    "–ê–≤—Ç–æ–º–æ–π–∫–∞",
                    "–ê–¥—Ä–µ—Å",
                    "total",
                    "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏",
                    "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏",
                ]
            ].sort_values("total", ascending=False),
            use_container_width=True,
        )


if __name__ == "__main__":
    main()