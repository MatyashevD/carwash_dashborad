import streamlit as st
import pandas as pd
import numpy as np

YANDEX_PHONE = "133133133133"


@st.cache_data
def load_data(file) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç CSV –≤ —Ñ–æ—Ä–º–∞—Ç–µ orderTable, –ø—Ä–∏–≤–æ–¥–∏—Ç —á–∏—Å–ª–∞ –∏ –¥–∞—Ç—ã."""
    # –ß–∏—Ç–∞–µ–º CSV –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é –≤ —Ç–µ–ª–µ—Ñ–æ–Ω–∞—Ö
    df = pd.read_csv(file, sep=";", encoding="utf-8-sig", dtype=str)

    # –ü—Ä–∏–≤–æ–¥–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    num_cols = [
        "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å",
        "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏",
        "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏",
        "–ù–∞—á–∏—Å–ª–µ–Ω–æ –∫–µ—à–±–µ–∫–∞",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace("\u00a0", " ", regex=False)
                .str.replace(" ", "", regex=False)
                .str.replace(",", ".", regex=False)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0.0)

    # –î–∞—Ç—ã / –≤—Ä–µ–º—è
    df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"] = pd.to_datetime(df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"], errors="coerce")
    df["date"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.date
    df["hour"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.hour
    df["weekday"] = df["–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã"].dt.weekday

    # –ò—Ç–æ–≥–æ–≤—ã–π —á–µ–∫
    df["total"] = df.get("–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏", 0) + df.get("–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏", 0)

    # –ö–ª—é—á –º–æ–π–∫–∏ (–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å)
    df["–ü–∞—Ä—Ç–Ω—ë—Ä"] = df["–ü–∞—Ä—Ç–Ω—ë—Ä"].fillna("")
    df["–ê–≤—Ç–æ–º–æ–π–∫–∞"] = df["–ê–≤—Ç–æ–º–æ–π–∫–∞"].fillna("")
    df["–ê–¥—Ä–µ—Å"] = df["–ê–¥—Ä–µ—Å"].fillna("")
    df["wash_key"] = df["–ü–∞—Ä—Ç–Ω—ë—Ä"] + " | " + df["–ê–≤—Ç–æ–º–æ–π–∫–∞"] + " | " + df["–ê–¥—Ä–µ—Å"]

    return df


def normalize_phone(phone) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é –∏ —É–±–∏—Ä–∞–µ—Ç –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã."""
    phone_str = str(phone).strip()
    
    # –ï—Å–ª–∏ —ç—Ç–æ NaN –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    if phone_str.lower() in ['nan', 'none', '']:
        return ""
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1.33133e+11" –∏–ª–∏ "1,33133E+11")
    try:
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
        phone_clean = phone_str.replace(",", ".")
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ float, –∑–∞—Ç–µ–º –≤ int
        phone_float = float(phone_clean)
        phone_int = int(phone_float)
        return str(phone_int)
    except (ValueError, OverflowError):
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å (–Ω–µ —á–∏—Å–ª–æ), —É–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
        phone_str = ''.join(filter(str.isdigit, phone_str))
        return phone_str


def categorize_by_phone(phone: str) -> str:
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É: –Ø–Ω–¥–µ–∫—Å (133133133133) –∏–ª–∏ –õ–µ–π–∫–∞ (–≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ)."""
    phone_normalized = normalize_phone(phone)
    if phone_normalized == YANDEX_PHONE:
        return "–Ø–Ω–¥–µ–∫—Å"
    return "–õ–µ–π–∫–∞"


def compare_washes(df1, df2, name1, name2):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–π–∫–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞–º–∏."""
    washes1 = set(df1["wash_key"].dropna().unique())
    washes2 = set(df2["wash_key"].dropna().unique())
    
    only_in_1 = washes1 - washes2  # –ú–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º —Ñ–∞–π–ª–µ
    only_in_2 = washes2 - washes1  # –ú–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ç–æ—Ä–æ–º —Ñ–∞–π–ª–µ
    common = washes1 & washes2      # –û–±—â–∏–µ –º–æ–π–∫–∏
    
    return {
        "only_in_1": sorted(only_in_1),
        "only_in_2": sorted(only_in_2),
        "common": sorted(common),
        "count_1": len(washes1),
        "count_2": len(washes2),
        "count_common": len(common),
    }


def main():
    st.set_page_config(page_title="Carwash Dashboard", layout="wide")
    st.title("–î–∞—à–±–æ—Ä–¥ –ø–æ –∞–≤—Ç–æ–º–æ–π–∫–∞–º (orderTable)")

    st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö CSV
    uploaded_files = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV-—Ñ–∞–π–ª–æ–≤ `orderTable`",
        type=["csv"],
        accept_multiple_files=True,
    )

    if not uploaded_files:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV-—Ñ–∞–π–ª, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –¥–∞—à–±–æ—Ä–¥.")
        st.stop()

    # –í—ã–±–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    file_labels = [f.name for f in uploaded_files]
    selected_label = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", file_labels)
    selected_file = next(f for f in uploaded_files if f.name == selected_label)

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ)
    if len(uploaded_files) > 1:
        st.sidebar.markdown("---")
        st.sidebar.subheader("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤")
        
        compare_file1 = st.sidebar.selectbox(
            "–ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª (–±–∞–∑–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥)",
            file_labels,
            index=0,
            key="compare_file1"
        )
        compare_file2 = st.sidebar.selectbox(
            "–í—Ç–æ—Ä–æ–π —Ñ–∞–π–ª (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–π –ø–µ—Ä–∏–æ–¥)",
            file_labels,
            index=min(1, len(file_labels) - 1),
            key="compare_file2"
        )
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤
        if compare_file1 != compare_file2:
            df1_compare = load_data(next(f for f in uploaded_files if f.name == compare_file1))
            df2_compare = load_data(next(f for f in uploaded_files if f.name == compare_file2))
            
            comparison = compare_washes(df1_compare, df2_compare, compare_file1, compare_file2)
            
            st.sidebar.write(f"**{compare_file1}:** {comparison['count_1']} –º–æ–µ–∫")
            st.sidebar.write(f"**{compare_file2}:** {comparison['count_2']} –º–æ–µ–∫")
            st.sidebar.write(f"**–û–±—â–∏—Ö –º–æ–µ–∫:** {comparison['count_common']}")
            
            if len(comparison['only_in_1']) > 0:
                st.sidebar.warning(f"‚ö†Ô∏è **–ò—Å—á–µ–∑–ª–æ –º–æ–µ–∫:** {len(comparison['only_in_1'])}")
            if len(comparison['only_in_2']) > 0:
                st.sidebar.info(f"‚ÑπÔ∏è **–ü–æ—è–≤–∏–ª–æ—Å—å –º–æ–µ–∫:** {len(comparison['only_in_2'])}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ session state –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            st.session_state['comparison'] = comparison
            st.session_state['compare_names'] = (compare_file1, compare_file2)

    df = load_data(selected_file)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –î–û —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    df = df.assign(
        partner_category=df["–¢–µ–ª–µ—Ñ–æ–Ω"].apply(categorize_by_phone)
    )
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏)
    with st.sidebar.expander("üîç –û—Ç–ª–∞–¥–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏", expanded=False):
        st.write(f"**–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df)}")
        st.write(f"**–õ–µ–π–∫–∞:** {len(df[df['partner_category'] == '–õ–µ–π–∫–∞'])}")
        st.write(f"**–Ø–Ω–¥–µ–∫—Å:** {len(df[df['partner_category'] == '–Ø–Ω–¥–µ–∫—Å'])}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        sample_phones = df["–¢–µ–ª–µ—Ñ–æ–Ω"].head(10).apply(normalize_phone).unique()
        st.write(f"**–ü—Ä–∏–º–µ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ (–ø–µ—Ä–≤—ã–µ 10):**")
        for phone in sample_phones[:10]:
            st.write(f"- `{phone}`")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω 133133133133 –≤ –¥–∞–Ω–Ω—ã—Ö
        all_phones_normalized = df["–¢–µ–ª–µ—Ñ–æ–Ω"].apply(normalize_phone)
        yandex_count = (all_phones_normalized == YANDEX_PHONE).sum()
        st.write(f"**–ó–∞–ø–∏—Å–µ–π —Å —Ç–µ–ª–µ—Ñ–æ–Ω–æ–º {YANDEX_PHONE}:** {yandex_count}")

    st.sidebar.markdown("---")
    st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")

    # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
    min_date = df["date"].min()
    max_date = df["date"].max()
    date_range = st.sidebar.date_input(
        "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
    )
    if isinstance(date_range, tuple):
        start_date, end_date = date_range
    else:
        start_date = end_date = date_range

    # –ò—Å–∫–ª—é—á–∏—Ç—å –Ø–Ω–¥–µ–∫—Å
    exclude_yandex = st.sidebar.checkbox(
        "–ò—Å–∫–ª—é—á–∏—Ç—å –Ø–Ω–¥–µ–∫—Å (133133133133)", value=False
    )

    filtered = df.copy()
    if exclude_yandex:
        filtered = filtered[filtered["partner_category"] != "–Ø–Ω–¥–µ–∫—Å"]

    # –§–∏–ª—å—Ç—Ä—ã –ø–æ –ø–∞—Ä—Ç–Ω—ë—Ä—É / –∞–≤—Ç–æ–º–æ–π–∫–µ / –∞–¥—Ä–µ—Å—É
    partners = sorted(
        [p for p in filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].dropna().unique().tolist() if p]
    )
    partner_sel = st.sidebar.multiselect("–ü–∞—Ä—Ç–Ω—ë—Ä", partners)

    washes = sorted(
        [w for w in filtered["–ê–≤—Ç–æ–º–æ–π–∫–∞"].dropna().unique().tolist() if w]
    )
    wash_sel = st.sidebar.multiselect("–ê–≤—Ç–æ–º–æ–π–∫–∞", washes)

    addresses = sorted(
        [a for a in filtered["–ê–¥—Ä–µ—Å"].dropna().unique().tolist() if a]
    )
    addr_sel = st.sidebar.multiselect("–ê–¥—Ä–µ—Å", addresses)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
    mask = (filtered["date"] >= start_date) & (filtered["date"] <= end_date)

    if partner_sel:
        mask &= filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].isin(partner_sel)
    if wash_sel:
        mask &= filtered["–ê–≤—Ç–æ–º–æ–π–∫–∞"].isin(wash_sel)
    if addr_sel:
        mask &= filtered["–ê–¥—Ä–µ—Å"].isin(addr_sel)

    filtered = filtered[mask]

    st.caption(
        f"–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: **{selected_label}**, –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤: **{len(filtered)}**"
    )

    if filtered.empty:
        st.warning("–ü–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        st.stop()

    # --- KPI-–±–ª–æ–∫ ---
    st.subheader("–û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")

    unique_clients = (
        filtered["–¢–µ–ª–µ—Ñ–æ–Ω"].astype(str).str.strip().nunique()
    )
    unique_washes_partner_addr = (
        filtered[["–ü–∞—Ä—Ç–Ω—ë—Ä", "–ê–¥—Ä–µ—Å"]]
        .dropna(subset=["–ê–¥—Ä–µ—Å"])
        .drop_duplicates()
        .shape[0]
    )

    total_cash = filtered["–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏"].sum()
    total_bonus = filtered["–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏"].sum()
    total_sum = filtered["total"].sum()
    cashback_sum = filtered["–ù–∞—á–∏—Å–ª–µ–Ω–æ –∫–µ—à–±–µ–∫–∞"].sum()

    avg_check = filtered["total"].mean()
    median_check = filtered["total"].median()
    bonus_share = total_bonus / total_sum * 100 if total_sum > 0 else 0.0

    col1, col2, col3, col4 = st.columns(4)
    col1.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã",
        f"{unique_clients:,}".replace(",", " "),
    )
    col2.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–π–∫–∏ (–ü–∞—Ä—Ç–Ω—ë—Ä+–ê–¥—Ä–µ—Å)",
        f"{unique_washes_partner_addr}",
    )
    col3.metric(
        "–í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π",
        f"{len(filtered):,}".replace(",", " "),
    )
    col4.metric(
        "–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ (‚ÇΩ)",
        f"{avg_check:,.2f}".replace(",", " "),
    )

    col5, col6, col7, col8 = st.columns(4)
    col5.metric(
        "–ò—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ (‚ÇΩ)",
        f"{total_sum:,.0f}".replace(",", " "),
    )
    col6.metric(
        "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏ (‚ÇΩ)",
        f"{total_cash:,.0f}".replace(",", " "),
    )
    col7.metric(
        "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏ (‚ÇΩ)",
        f"{total_bonus:,.0f}".replace(",", " "),
    )
    col8.metric("–î–æ–ª—è –±–æ–Ω—É—Å–æ–≤ (%)", f"{bonus_share:.2f}")

    st.markdown(
        f"**–ú–µ–¥–∏–∞–Ω–Ω—ã–π —á–µ–∫:** {median_check:.2f} ‚ÇΩ &nbsp;&nbsp;|&nbsp;&nbsp; "
        f"**–°—É–º–º–∞ –∫–µ—à–±–µ–∫–∞:** {cashback_sum:,.0f} ‚ÇΩ".replace(",", " ")
    )

    # –í—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å" –∫–∞–∫ –≤ –≥—Ä–∞—Ñ–∏–∫–µ)
    leyka_total = filtered.loc[
        filtered["partner_category"] == "–õ–µ–π–∫–∞", "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å"
    ].sum()
    yandex_total = filtered.loc[
        filtered["partner_category"] == "–Ø–Ω–¥–µ–∫—Å", "–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å"
    ].sum()
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    leyka_count = len(filtered[filtered["partner_category"] == "–õ–µ–π–∫–∞"])
    yandex_count = len(filtered[filtered["partner_category"] == "–Ø–Ω–¥–µ–∫—Å"])
    
    col_partner1, col_partner2 = st.columns(2)
    col_partner1.metric(
        "–í—ã—Ä—É—á–∫–∞ –õ–µ–π–∫–∞ (‚ÇΩ)",
        f"{leyka_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {leyka_count}"
    )
    col_partner2.metric(
        "–í—ã—Ä—É—á–∫–∞ –Ø–Ω–¥–µ–∫—Å (‚ÇΩ)",
        f"{yandex_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {yandex_count}"
    )

    # --- –ü–æ–¥–ø–∏—Å–∫–∏ (FranchisingGroup) ---
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å –ø–∞—Ä—Ç–Ω—ë—Ä–æ–º FranchisingGroup (—É—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è)
    subscription_mask = filtered["–ü–∞—Ä—Ç–Ω—ë—Ä"].astype(str).str.strip().str.lower().str.contains("franchisinggroup", case=False, na=False)
    subscription_data = filtered[subscription_mask]
    
    subscription_total = subscription_data["–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å"].sum()
    subscription_unique_clients = subscription_data["–¢–µ–ª–µ—Ñ–æ–Ω"].astype(str).str.strip().nunique()
    subscription_count = len(subscription_data)
    
    st.markdown("---")
    st.subheader("üìã –ü–æ–¥–ø–∏—Å–∫–∏ (FranchisingGroup)")
    col_sub1, col_sub2 = st.columns(2)
    col_sub1.metric(
        "–°—É–º–º–∞ –æ–ø–ª–∞—á–µ–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–æ–∫ (‚ÇΩ)",
        f"{subscription_total:,.0f}".replace(",", " "),
        help=f"–ó–∞–ø–∏—Å–µ–π: {subscription_count}"
    )
    col_sub2.metric(
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–æ–¥–ø–∏—Å–∫–æ–π",
        f"{subscription_unique_clients:,}".replace(",", " "),
        help=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"
    )

    # --- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ KPI) ---
    if 'comparison' in st.session_state and 'compare_names' in st.session_state:
        comparison = st.session_state['comparison']
        name1, name2 = st.session_state['compare_names']
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—á–µ–∑–Ω—É–≤—à–∏–µ –º–æ–π–∫–∏ —Å—Ä–∞–∑—É, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if comparison['only_in_1']:
            st.markdown("---")
            st.error(f"‚ö†Ô∏è **–í–ù–ò–ú–ê–ù–ò–ï: {len(comparison['only_in_1'])} –º–æ–π–∫–∞(–∏) –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ {name2} –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å {name1}**")
            
            st.subheader(f"‚ùå –ú–æ–π–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å—á–µ–∑–ª–∏ –≤ {name2}:")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            missing_washes_df = pd.DataFrame({
                "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å": comparison['only_in_1']
            })
            st.dataframe(missing_washes_df, use_container_width=True, hide_index=True)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            col_comp1, col_comp2, col_comp3 = st.columns(3)
            col_comp1.metric(f"–ú–æ–µ–∫ –≤ {name1}", comparison['count_1'])
            col_comp2.metric(f"–ú–æ–µ–∫ –≤ {name2}", comparison['count_2'])
            col_comp3.metric("–û–±—â–∏—Ö –º–æ–µ–∫", comparison['count_common'])
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—è–≤–∏–≤—à–∏–µ—Å—è –º–æ–π–∫–∏ (–º–µ–Ω–µ–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
        if comparison['only_in_2']:
            st.markdown("---")
            st.info(f"‚ÑπÔ∏è **–ù–æ–≤—ã–µ –º–æ–π–∫–∏ –≤ {name2} ({len(comparison['only_in_2'])}):**")
            new_washes_df = pd.DataFrame({
                "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å": comparison['only_in_2']
            })
            st.dataframe(new_washes_df, use_container_width=True, hide_index=True)

    # --- –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –¥–Ω—è–º ---
    st.markdown("---")
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –¥–Ω—è–º")

    daily = (
        filtered.groupby("date")
        .agg(
            orders=("‚Ññ", "count"),
            revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"),
        )
        .reset_index()
        .sort_values("date")
    )

    col_d1, col_d2 = st.columns(2)
    col_d1.line_chart(
        daily.set_index("date")["orders"], use_container_width=True
    )
    col_d1.caption("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤ –ø–æ –¥–Ω—è–º")

    col_d2.line_chart(
        daily.set_index("date")["revenue"], use_container_width=True
    )
    col_d2.caption("–í—ã—Ä—É—á–∫–∞ –ø–æ –¥–Ω—è–º (–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å)")

    st.markdown("---")
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ –≤—ã—Ä—É—á–∫–∏ –õ–µ–π–∫–∞ vs –Ø–Ω–¥–µ–∫—Å")

    partner_daily = (
        filtered[filtered["partner_category"].isin(["–õ–µ–π–∫–∞", "–Ø–Ω–¥–µ–∫—Å"])]
        .groupby(["date", "partner_category"])
        .agg(revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"))
        .reset_index()
    )

    if partner_daily.empty:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –õ–µ–π–∫–∞ –∏ –Ø–Ω–¥–µ–∫—Å.")
    else:
        partner_pivot = (
            partner_daily.pivot(
                index="date", columns="partner_category", values="revenue"
            )
            .fillna(0)
            .sort_index()
        )
        st.line_chart(partner_pivot, use_container_width=True)
        st.caption(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—É–º–º–∞—Ä–Ω–æ–π –≤—ã—Ä—É—á–∫–∏ (–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å) –ø–æ –¥–Ω—è–º –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –õ–µ–π–∫–∞ –∏ –Ø–Ω–¥–µ–∫—Å."
        )

    # --- –¢–æ–ø –º–æ–π–∫–∏ ---
    st.markdown("---")
    st.subheader("–¢–æ–ø‚Äë–º–æ–π–∫–∏")

    top_wash = (
        filtered.groupby("wash_key")
        .agg(
            orders=("‚Ññ", "count"),
            revenue=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "sum"),
            avg_check=("–ü–æ—Å—Ç—É–ø–∏–ª–æ –Ω–∞ –±–æ–∫—Å", "mean"),
        )
        .reset_index()
        .sort_values("revenue", ascending=False)
    )

    st.markdown("**–¢–æ–ø‚Äë10 –º–æ–µ–∫ –ø–æ –≤—ã—Ä—É—á–∫–µ:**")
    st.dataframe(
        top_wash.head(10).rename(
            columns={
                "wash_key": "–ü–∞—Ä—Ç–Ω—ë—Ä | –ê–≤—Ç–æ–º–æ–π–∫–∞ | –ê–¥—Ä–µ—Å",
                "orders": "–ó–∞–∫–∞–∑–æ–≤",
                "revenue": "–í—ã—Ä—É—á–∫–∞",
                "avg_check": "–°—Ä. —á–µ–∫",
            }
        ),
        use_container_width=True,
    )

    # --- –í—ã–±—Ä–æ—Å—ã ---
    st.markdown("---")
    st.subheader("–í—ã–±—Ä–æ—Å—ã –ø–æ —Å—É–º–º–µ —á–µ–∫–∞")

    amounts = filtered["total"].values
    q1 = np.percentile(amounts, 25)
    q3 = np.percentile(amounts, 75)
    iqr = q3 - q1
    upper = q3 + 1.5 * iqr
    outliers = filtered[filtered["total"] > upper]

    st.markdown(
        f"Q1 = {q1:.2f} ‚ÇΩ, Q3 = {q3:.2f} ‚ÇΩ, –ø–æ—Ä–æ–≥ –≤—ã–±—Ä–æ—Å–∞ = {upper:.2f} ‚ÇΩ, "
        f"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ = {len(outliers)}"
    )

    show_outliers = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –≤—ã–±—Ä–æ—Å–æ–≤", value=False)
    if show_outliers and not outliers.empty:
        st.dataframe(
            outliers[
                [
                    "–î–∞—Ç–∞ –æ–ø–ª–∞—Ç—ã",
                    "–¢–µ–ª–µ—Ñ–æ–Ω",
                    "–ö–ª–∏–µ–Ω—Ç",
                    "–ü–∞—Ä—Ç–Ω—ë—Ä",
                    "–ê–≤—Ç–æ–º–æ–π–∫–∞",
                    "–ê–¥—Ä–µ—Å",
                    "total",
                    "–û–ø–ª–∞—á–µ–Ω–æ –¥–µ–Ω—å–≥–∞–º–∏",
                    "–û–ø–ª–∞—á–µ–Ω–æ –±–æ–Ω—É—Å–∞–º–∏",
                ]
            ].sort_values("total", ascending=False),
            use_container_width=True,
        )


if __name__ == "__main__":
    main()